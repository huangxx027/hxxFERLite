{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CpN7re7_aMc4"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "训练脚本，由于数据集不大，这里一次性读入内存\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vklRSPhtcQB7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "读取数据集\n",
    "\"\"\"\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "\n",
    "class Fer2013(object):\n",
    "    def __init__(self, folder=\"../dataset/fer2013\"):\n",
    "        \"\"\"\n",
    "        构造函数\n",
    "        \"\"\"\n",
    "        self.folder = folder\n",
    "\n",
    "    def gen_train(self):\n",
    "        \"\"\"\n",
    "        产生训练数据\n",
    "        :return expressions:读取文件的顺序即标签的下标对应\n",
    "        :return x_train: 训练数据集\n",
    "        :return y_train： 训练标签\n",
    "        \"\"\"\n",
    "        #\n",
    "        folder = os.path.join(self.folder, 'Training')\n",
    "        #定义表情的文件夹\n",
    "        expressions = ['anger', 'disgust', 'fear', 'happy', 'sad', 'surprised', 'neutral', 'contempt']\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        #tdqm加载进度条\n",
    "        for i in tqdm(range(len(expressions))):\n",
    "            #contempt表情并没有对应的训练集\n",
    "            if expressions[i] == 'contempt':\n",
    "                continue\n",
    "            #每个表情生成一个文件夹\n",
    "            expression_folder = os.path.join(folder, expressions[i])\n",
    "            #images为返回每个表情对应的文件夹的列表\n",
    "            images = os.listdir(expression_folder)\n",
    "            #遍历每个表情对应的文件夹中的图片\n",
    "            for j in range(len(images)):\n",
    "                #读取48*48的灰度图\n",
    "                img = load_img(os.path.join(expression_folder, images[j]), target_size=(48, 48), color_mode=\"grayscale\")\n",
    "                img = img_to_array(img)  # 灰度化\n",
    "                #往x_train数组中添加元素\n",
    "                x_train.append(img)\n",
    "                y_train.append(i)\n",
    "        #https://blog.csdn.net/qq_40247705/article/details/104756991\n",
    "        #使用float32减少空间占用\n",
    "        x_train = np.array(x_train).astype('float32') / 255.\n",
    "        y_train = np.array(y_train).astype('int')\n",
    "        return expressions, x_train, y_train\n",
    "\n",
    "    def gen_valid(self):\n",
    "        \"\"\"\n",
    "        产生验证集数据\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        folder = os.path.join(self.folder, 'PublicTest')\n",
    "        expressions = ['anger', 'disgust', 'fear', 'happy', 'sad', 'surprised', 'neutral', 'contempt']\n",
    "        x_valid = []\n",
    "        y_valid = []\n",
    "        for i in tqdm(range(len(expressions))):\n",
    "            if expressions[i] == 'contempt':\n",
    "                continue\n",
    "            expression_folder = os.path.join(folder, expressions[i])\n",
    "            images = os.listdir(expression_folder)\n",
    "            for j in range(len(images)):\n",
    "                img = load_img(os.path.join(expression_folder, images[j]), target_size=(48, 48), color_mode=\"grayscale\")\n",
    "                img = img_to_array(img)  # 灰度化\n",
    "                x_valid.append(img)\n",
    "                y_valid.append(i)\n",
    "        x_valid = np.array(x_valid).astype('float32') / 255.\n",
    "        y_valid = np.array(y_valid).astype('int')\n",
    "        return expressions, x_valid, y_valid\n",
    "\n",
    "    def     gen_test(self):\n",
    "        \"\"\"\n",
    "        产生验证集数据\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        folder = os.path.join(self.folder, 'PrivateTest')\n",
    "        expressions = ['anger', 'disgust', 'fear', 'happy', 'sad', 'surprised', 'neutral', 'contempt']\n",
    "        x_test = []\n",
    "        y_test = []\n",
    "        for i in tqdm(range(len(expressions))):\n",
    "            if expressions[i] == 'contempt':\n",
    "                continue\n",
    "            expression_folder = os.path.join(folder, expressions[i])\n",
    "            images = os.listdir(expression_folder)\n",
    "            for j in range(len(images)):\n",
    "                img = load_img(os.path.join(expression_folder, images[j]), target_size=(48, 48), color_mode=\"grayscale\")\n",
    "                img = img_to_array(img)  # 灰度化\n",
    "                x_test.append(img)\n",
    "                y_test.append(i)\n",
    "        x_test = np.array(x_test).astype('float32') / 255.\n",
    "        y_test = np.array(y_test).astype('int')\n",
    "        return expressions, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "X2_lac8LcLVs"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构建CNN模型\n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense, AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import PReLU\n",
    "\n",
    "\n",
    "def CNN1(input_shape=(48, 48, 1), n_classes=8):\n",
    "    \"\"\"\n",
    "    参考VGG思路设计的第一个模型，主要注意点是感受野不能太大，以免获得很多噪声信息\n",
    "    :param input_shape: 输入图片的尺寸\n",
    "    :param n_classes: 目标类别数目\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # input\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    # block1\n",
    "    x = Conv2D(32, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(input_layer)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # block2\n",
    "    x = Conv2D(64, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # block3\n",
    "    x = Conv2D(128, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # fc\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def CNN2(input_shape=(48, 48, 1), n_classes=8):\n",
    "    \"\"\"\n",
    "    参考论文Going deeper with convolutions在输入层后加一层的1*1卷积增加非线性表示\n",
    "\n",
    "    :param input_shape:\n",
    "    :param n_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # input\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    # block1\n",
    "    x = Conv2D(32, (1, 1), strides=1, padding='same', activation='relu')(input_layer)\n",
    "    x = Conv2D(32, (5, 5), strides=1, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    # block2\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    # block3\n",
    "    x = Conv2D(64, (5, 5), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    # fc\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def CNN3(input_shape=(48, 48, 1), n_classes=8):\n",
    "    \"\"\"\n",
    "    参考论文实现\n",
    "    A Compact Deep Learning Model for Robust Facial Expression Recognition\n",
    "    https://blog.csdn.net/lynlindasy/article/details/100094333\n",
    "    :param input_shape:\n",
    "    :param n_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # input activation function为relu，步长为1，padding为赋值一样的值\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (1, 1), strides=1, padding='same', activation='relu')(input_layer)\n",
    "    # block1 PRelu指的是带参数的ReLU函数 https://blog.csdn.net/shuzfan/article/details/51345832\n",
    "    x = Conv2D(64, (3, 3), strides=1, padding='same')(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Conv2D(64, (5, 5), strides=1, padding='same')(x)\n",
    "    x = PReLU()(x)\n",
    "    #最大池化\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    # block2 重复一次block1\n",
    "    x = Conv2D(64, (3, 3), strides=1, padding='same')(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Conv2D(64, (5, 5), strides=1, padding='same')(x)\n",
    "    x = PReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    # fully-connected 64经过两次全连接层，并且dropout = 0.6，最后经过一个sofmax分类器\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFv14l9rbPsl",
    "outputId": "bc50873c-a294-45b1-e635-22a53072d8fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:16<00:00,  2.02s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  4.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.80it/s]\n"
     ]
    }
   ],
   "source": [
    "#当训练接为fer2013时\n",
    "expressions, x_train, y_train = Fer2013().gen_train()\n",
    "_, x_valid, y_valid = Fer2013().gen_valid()\n",
    "_, x_test, y_test = Fer2013().gen_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "88NW8tBUxueG",
    "outputId": "ea8ef548-6de9-4f9e-e155-d0734d4341d8"
   },
   "outputs": [],
   "source": [
    "# target编码\n",
    "y_train = to_categorical(y_train).reshape(y_train.shape[0], -1)\n",
    "y_valid = to_categorical(y_valid).reshape(y_valid.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "z2EkPhTYxTYt",
    "outputId": "dbcc6fdc-d865-4c2d-aa9d-8d0ba9cf3cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load fer2013 dataset successfully, it has 28709 train images and 3589 valid iamges\n"
     ]
    }
   ],
   "source": [
    "# 为了统一几个数据集，必须增加一列为0的，训练集合验证集的第一列表情一律为0\n",
    "y_train = np.hstack((y_train, np.zeros((y_train.shape[0], 1))))\n",
    "y_valid = np.hstack((y_valid, np.zeros((y_valid.shape[0], 1))))\n",
    "print(\"load fer2013 dataset successfully, it has {} train images and {} valid iamges\".format(y_train.shape[0], y_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88NKcE2kcH6K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "C:\\python\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      " 85/897 [=>............................] - ETA: 24:09 - loss: 2.0894 - accuracy: 0.093 - ETA: 13:06 - loss: 2.0841 - accuracy: 0.109 - ETA: 13:51 - loss: 2.0815 - accuracy: 0.114 - ETA: 15:38 - loss: 2.0781 - accuracy: 0.140 - ETA: 17:36 - loss: 2.0759 - accuracy: 0.156 - ETA: 18:20 - loss: 2.0703 - accuracy: 0.182 - ETA: 18:49 - loss: 2.0677 - accuracy: 0.187 - ETA: 18:50 - loss: 2.0613 - accuracy: 0.203 - ETA: 19:05 - loss: 2.0576 - accuracy: 0.211 - ETA: 19:04 - loss: 2.0480 - accuracy: 0.225 - ETA: 19:04 - loss: 2.0447 - accuracy: 0.221 - ETA: 19:11 - loss: 2.0318 - accuracy: 0.234 - ETA: 19:15 - loss: 2.0268 - accuracy: 0.233 - ETA: 18:51 - loss: 2.0074 - accuracy: 0.241 - ETA: 18:37 - loss: 2.0175 - accuracy: 0.239 - ETA: 19:01 - loss: 2.0074 - accuracy: 0.244 - ETA: 18:45 - loss: 1.9979 - accuracy: 0.242 - ETA: 18:25 - loss: 1.9914 - accuracy: 0.239 - ETA: 18:19 - loss: 1.9816 - accuracy: 0.238 - ETA: 18:02 - loss: 1.9737 - accuracy: 0.237 - ETA: 17:51 - loss: 1.9697 - accuracy: 0.233 - ETA: 17:34 - loss: 1.9622 - accuracy: 0.233 - ETA: 17:21 - loss: 1.9545 - accuracy: 0.232 - ETA: 17:07 - loss: 1.9517 - accuracy: 0.234 - ETA: 16:55 - loss: 1.9483 - accuracy: 0.233 - ETA: 16:43 - loss: 1.9430 - accuracy: 0.238 - ETA: 16:31 - loss: 1.9457 - accuracy: 0.236 - ETA: 16:22 - loss: 1.9416 - accuracy: 0.236 - ETA: 16:12 - loss: 1.9357 - accuracy: 0.239 - ETA: 16:03 - loss: 1.9327 - accuracy: 0.239 - ETA: 15:55 - loss: 1.9295 - accuracy: 0.239 - ETA: 15:47 - loss: 1.9279 - accuracy: 0.240 - ETA: 15:40 - loss: 1.9257 - accuracy: 0.239 - ETA: 15:33 - loss: 1.9256 - accuracy: 0.236 - ETA: 15:26 - loss: 1.9234 - accuracy: 0.234 - ETA: 15:20 - loss: 1.9204 - accuracy: 0.236 - ETA: 15:16 - loss: 1.9162 - accuracy: 0.238 - ETA: 15:10 - loss: 1.9130 - accuracy: 0.238 - ETA: 15:07 - loss: 1.9127 - accuracy: 0.237 - ETA: 15:03 - loss: 1.9079 - accuracy: 0.237 - ETA: 15:00 - loss: 1.9046 - accuracy: 0.237 - ETA: 14:59 - loss: 1.9037 - accuracy: 0.239 - ETA: 14:57 - loss: 1.9052 - accuracy: 0.239 - ETA: 14:55 - loss: 1.9021 - accuracy: 0.240 - ETA: 14:52 - loss: 1.9030 - accuracy: 0.239 - ETA: 14:49 - loss: 1.9007 - accuracy: 0.239 - ETA: 14:47 - loss: 1.8986 - accuracy: 0.240 - ETA: 14:45 - loss: 1.8985 - accuracy: 0.240 - ETA: 14:41 - loss: 1.8976 - accuracy: 0.238 - ETA: 14:38 - loss: 1.8971 - accuracy: 0.237 - ETA: 14:35 - loss: 1.8977 - accuracy: 0.235 - ETA: 14:33 - loss: 1.8969 - accuracy: 0.235 - ETA: 14:35 - loss: 1.8964 - accuracy: 0.233 - ETA: 14:33 - loss: 1.8945 - accuracy: 0.234 - ETA: 14:31 - loss: 1.8953 - accuracy: 0.234 - ETA: 14:31 - loss: 1.8939 - accuracy: 0.234 - ETA: 14:28 - loss: 1.8914 - accuracy: 0.236 - ETA: 14:25 - loss: 1.8931 - accuracy: 0.233 - ETA: 14:23 - loss: 1.8926 - accuracy: 0.233 - ETA: 14:20 - loss: 1.8931 - accuracy: 0.233 - ETA: 14:17 - loss: 1.8909 - accuracy: 0.233 - ETA: 14:15 - loss: 1.8898 - accuracy: 0.231 - ETA: 14:12 - loss: 1.8885 - accuracy: 0.234 - ETA: 14:10 - loss: 1.8878 - accuracy: 0.234 - ETA: 14:07 - loss: 1.8873 - accuracy: 0.232 - ETA: 14:05 - loss: 1.8854 - accuracy: 0.233 - ETA: 14:02 - loss: 1.8855 - accuracy: 0.232 - ETA: 14:00 - loss: 1.8844 - accuracy: 0.233 - ETA: 13:58 - loss: 1.8824 - accuracy: 0.235 - ETA: 13:57 - loss: 1.8831 - accuracy: 0.236 - ETA: 13:55 - loss: 1.8831 - accuracy: 0.234 - ETA: 13:53 - loss: 1.8818 - accuracy: 0.235 - ETA: 13:52 - loss: 1.8804 - accuracy: 0.236 - ETA: 13:50 - loss: 1.8795 - accuracy: 0.235 - ETA: 13:48 - loss: 1.8788 - accuracy: 0.235 - ETA: 13:47 - loss: 1.8776 - accuracy: 0.235 - ETA: 13:50 - loss: 1.8775 - accuracy: 0.235 - ETA: 13:51 - loss: 1.8771 - accuracy: 0.236 - ETA: 13:51 - loss: 1.8767 - accuracy: 0.236 - ETA: 13:50 - loss: 1.8762 - accuracy: 0.235 - ETA: 13:50 - loss: 1.8742 - accuracy: 0.237 - ETA: 13:50 - loss: 1.8767 - accuracy: 0.236 - ETA: 13:48 - loss: 1.8763 - accuracy: 0.235 - ETA: 13:46 - loss: 1.8751 - accuracy: 0.236 - ETA: 13:45 - loss: 1.8741 - accuracy: 0.2360"
     ]
    }
   ],
   "source": [
    "\n",
    "#以48*48的矩阵输入，因为是黑白，所以高度为1\n",
    "model = CNN3(input_shape=(48, 48, 1), n_classes=8)\n",
    "#使用随机梯度下降算法(https://blog.csdn.net/weixin_46301248/article/details/105883723)，同时定义loss为交叉熵形式计算\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "callback = [\n",
    "    #EarlyuStopping防止过拟合，因为表现不佳而备注\n",
    "    #     EarlyStopping(monitor='val_loss', patience=50, verbose=True),\n",
    "    #     ReduceLROnPlateau(monitor='lr', factor=0.1, patience=20, verbose=True),\n",
    "    ModelCheckpoint('../models/cnn2_best_weights.h5', monitor='val_accuracy', verbose=True, save_best_only=True,\n",
    "                    save_weights_only=True)]\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=10,\n",
    "                                      width_shift_range=0.05,\n",
    "                                      height_shift_range=0.05,\n",
    "                                      horizontal_flip=True,\n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2).flow(x_train, y_train, batch_size=32)\n",
    "valid_generator = ImageDataGenerator().flow(x_valid, y_valid, batch_size=32)\n",
    "history_fer2013 = model.fit_generator(train_generator,\n",
    "                                      steps_per_epoch=len(y_train) // 32,\n",
    "                                      epochs=32,\n",
    "                                      validation_data=valid_generator,\n",
    "                                      validation_steps=len(y_valid) // 32,\n",
    "                                      callbacks=callback)\n",
    "his = history_fer2013\n",
    "\n",
    "# test\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "print(\"test accuacy\", np.sum(pred.reshape(-1) == y_test.reshape(-1)) / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_ZbPKamb-6o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
